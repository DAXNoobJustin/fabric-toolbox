{"cells":[{"cell_type":"markdown","source":["**Install semantic link labs**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"29733b6f-2b10-49e8-acec-6984fcb3e5e4"},{"cell_type":"code","source":["!pip install semantic-link-labs --quiet"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5acd6578-510f-41ea-9f34-40093d5680d6"},{"cell_type":"markdown","source":["**Libraries**"],"metadata":{},"id":"6592e13a-2323-4d11-b107-c9f519194f46"},{"cell_type":"code","source":["import base64\n","import datetime as dt\n","import json\n","import os\n","import re\n","import struct\n","import time\n","from datetime import datetime, timedelta\n","from string import Template\n","from timeit import default_timer as timer\n","from typing import List, Optional, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","import pyodbc\n","import requests\n","import sqlalchemy\n","from IPython.display import Markdown, display\n","from notebookutils import mssparkutils\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col, current_timestamp, lit\n","\n","import com.microsoft.spark.fabric\n","from com.microsoft.spark.fabric.Constants import Constants\n","\n","import sempy.fabric as fabric\n","import sempy_labs as labs\n","import sempy_labs._icons as icons\n","from sempy import fabric\n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException\n","from sempy_labs._helper_functions import _decode_b64, lro, resolve_workspace_name_and_id\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4ec5ed38-9f17-43ef-a8a4-4deb1aaf853f"},{"cell_type":"markdown","source":["import sempy.fabric as fabric\n","import sempy_labs as labs\n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException\n","import json\n","import requests\n","import pandas as pd\n","import os\n","import datetime as dt\n","import time\n","from timeit import default_timer as timer\n","from datetime import datetime, timedelta\n","from string import Template\n","import base64\n","import re\n","import struct\n","import sqlalchemy\n","import pyodbc\n","from notebookutils import mssparkutils\n","import numpy as np\n","import sempy_labs as labs\n","from sempy import fabric\n","import com.microsoft.spark.fabric\n","from com.microsoft.spark.fabric.Constants import Constants\n","from IPython.display import display, Markdown\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col,current_timestamp,lit\n","from typing import Optional, Tuple, List\n","from sempy_labs._helper_functions import (resolve_workspace_name_and_id, lro, _decode_b64)\n","import sempy_labs._icons as icons"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"72cd894e-204f-4edf-b44c-55c422f24f72"},{"cell_type":"markdown","source":["**Fabric client**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"58ee6402-63b1-4b0b-a0db-1468dd8ab9d1"},{"cell_type":"code","source":["client = fabric.FabricRestClient()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6d3bdc3d-ae65-437b-9da7-c6968fce0d74"},{"cell_type":"markdown","source":["**Function to flatten a nested json**\n","- Takes a pandas dataframe\n","- Search for columns of type list\n","- flatten the list"],"metadata":{},"id":"cf1c96a9-36bb-433c-bdae-e74a751c903a"},{"cell_type":"code","source":["def flatten_nested_json_df(df):\n","\n","    df = df.reset_index()\n","\n","    # search for columns to explode/flatten\n","    s = (df.applymap(type) == list).all()\n","    list_columns = s[s].index.tolist()\n","\n","    s = (df.applymap(type) == dict).all()\n","    dict_columns = s[s].index.tolist()\n","\n","    while len(list_columns) > 0 or len(dict_columns) > 0:\n","        new_columns = []\n","\n","        for col in dict_columns:\n","\n","            horiz_exploded = pd.json_normalize(df[col]).add_prefix(f'{col}.')\n","            horiz_exploded.index = df.index\n","            df = pd.concat([df, horiz_exploded], axis=1).drop(columns=[col])\n","            new_columns.extend(horiz_exploded.columns) # inplace\n","\n","        for col in list_columns:\n","\n","            # explode lists vertically, adding new columns\n","            df = df.drop(columns=[col]).join(df[col].explode().to_frame())\n","            new_columns.append(col)\n","\n","        # check if there are still dict o list fields to flatten\n","        s = (df[new_columns].applymap(type) == list).all()\n","        list_columns = s[s].index.tolist()\n","\n","        s = (df[new_columns].applymap(type) == dict).all()\n","        dict_columns = s[s].index.tolist()\n","\n","    return df\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fd93c03f-f80f-4ef2-926b-dd87c937d60d"},{"cell_type":"markdown","source":["**Function to upper case the first letter of a string**"],"metadata":{},"id":"d651a897-4d09-42ed-acb7-6f08f6229659"},{"cell_type":"code","source":["def convert_into_uppercase(string_val):\n","    return string_val.group(1) + string_val.group(2).upper()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"49d6b1dd-edb0-4420-bd77-895292a3c8ca"},{"cell_type":"markdown","source":["**Function to split a string, take the last 2 items and capitalize their first character**\n","\n","Example: \n","input   -> 'datamarts.users.datamartUserAccessRight'\n","output  -> 'UsersDatamartUserAccessRight'\n","\n","or \n","input   -> 'datamarts.users'\n","output  -> 'DatamartsUsers'"],"metadata":{},"id":"7b8934ac-bdd6-4a07-8c03-de8fef552b52"},{"cell_type":"code","source":["def process_column_name(column_name, separator):\n","    list_values = column_name.split(separator)\n","\n","    len_list = len(list_values)\n","\n","    # iterate over the list\n","    for i in range(len(list_values)):\n","\n","        # current value \n","        current_value = list_values[i]\n","\n","        # upper case the first letter \n","        upper_case_value = re.sub(\"(^|\\s)(\\S)\", convert_into_uppercase, current_value) \n","\n","        # replace the column name in the dataframe\n","        list_values[i] = upper_case_value\n","\n","    list_values_joined = ''.join(list_values)\n","    return list_values_joined"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b159545-5345-479c-8471-fb6c5e5aa14a"},{"cell_type":"markdown","source":["**Time rounder**"],"metadata":{},"id":"390e0764-d917-4bf2-be3c-8c8c17d2ec4c"},{"cell_type":"code","source":["# function to round to the nearest 15min\n","def fnRoundMinDatetime(dt, delta):\n","    return datetime.min + round((dt - datetime.min) / delta) * delta\n","\n","def fnRoundHourDatetime(dt):\n","    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n","    return (dt.replace(second=0, microsecond=0, minute=0, hour=dt.hour)\n","               +timedelta(hours=dt.minute//30))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"feaef5dc-0e8d-4ecd-aa8d-51ef36519fcd"},{"cell_type":"markdown","source":["**Function to add a user to a fabric workspace**"],"metadata":{},"id":"e25aff1d-54ed-4a84-b92c-e6b14700da9a"},{"cell_type":"code","source":["def add_user_to_fabric_workspace(baseUrl, workspaceId, userUPN, accessToken, waitTime):\n","\n","    vWorkspaceId = workspaceId\n","    vBaseUrl = baseUrl\n","    vUserUPN = userUPN\n","    vAccessToken = accessToken\n","    vWaitTime = waitTime\n","\n","    # log activity\n","    vMessage = f\"adding user <{vUserUPN}> as admin to workspace <{vWorkspaceId}>\"\n","    print(vMessage)\n","\n","    # inputs for post request\n","    vHeader = {'Content-Type':'application/json','Authorization': f'Bearer {vAccessToken}'} \n","    vJsonBody = {\n","        \"groupUserAccessRight\": \"Admin\",\n","        \"emailAddress\": vUserUPN\n","    }\n","    vAssignUrl = \"admin/groups/\" + vWorkspaceId + \"/users\"\n","\n","\n","    try:\n","        # post the assignment\n","        assignment_response = requests.post(vBaseUrl + vAssignUrl, headers=vHeader, json=vJsonBody)\n","\n","        # raise an error for bad status codes\n","        assignment_response.raise_for_status()  \n","\n","        # get the status code and reason\n","        status_code = assignment_response.status_code\n","        status = assignment_response.reason\n","\n","        # check status\n","        if status_code == 200: \n","\n","            vMessage = f\"assigning user <{vUserUPN}> to workspace <{vWorkspaceId}> succeeded.\"\n","            print(f\"{vMessage}\")\n","            status = \"succeeded\"\n","            print(f\"sleeping {vWaitTime} seconds\")\n","            time.sleep(vWaitTime) # to avoid hitting the limit of the api\n","\n","    except requests.exceptions.HTTPError as errh: \n","        error_message = errh.args[0]\n","        vMessage = f\"assigning user <{vUserUPN}> to workspace <{vWorkspaceId}> failed. HTTP Error; error: <{error_message}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.ReadTimeout as errrt: \n","        vMessage = f\"assigning user <{vUserUPN}> to workspace <{vWorkspaceId}> failed. Time out; error: <{errrt}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.ConnectionError as conerr: \n","        vMessage = f\"assigning user <{vUserUPN}> to workspace <{vWorkspaceId}> failed. Connection error; error: <{conerr}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.RequestException as errex: \n","        vMessage = f\"assigning user <{vUserUPN}> to workspace <{vWorkspaceId}> failed. Exception request; error: <{errex}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","\n","    # return the status\n","    return status\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1685dbe1-8f48-4bd4-a509-3b1c05c49940"},{"cell_type":"markdown","source":["**Function to remove a user from a fabric workspace**"],"metadata":{},"id":"6be8a1dd-7b17-4d4d-bda7-9ca03a97fc14"},{"cell_type":"code","source":["def remove_user_from_fabric_workspace(baseUrl, workspaceId, userUPN, accessToken, waitTime):\n","\n","    vWorkspaceId = workspaceId\n","    vBaseUrl = baseUrl\n","    vUserUPN = userUPN\n","    vAccessToken = accessToken\n","    vWaitTime = waitTime\n","\n","    # log activity\n","    vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}>\"\n","    print(vMessage)\n","\n","\n","    # inputs for post request\n","    vHeader = {'Content-Type':'application/json','Authorization': f'Bearer {vAccessToken}'} \n","    vDeleteUrl = \"admin/groups/\" + vWorkspaceId + \"/users/\" + vUserUPN\n","\n","    try:\n","        # post the assignment\n","        assignment_response = requests.delete(vBaseUrl + vDeleteUrl, headers=vHeader)\n","\n","        # raise an error for bad status codes\n","        assignment_response.raise_for_status()  \n","\n","        # get the status code and reason\n","        status_code = assignment_response.status_code\n","        status = assignment_response.reason\n","\n","        # check status\n","        if status_code == 200: \n","\n","            vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}> succeeded.\"\n","            print(f\"{vMessage}\")\n","            status = \"succeeded\"\n","            print(f\"sleeping {vWaitTime} seconds\")\n","            time.sleep(vWaitTime) # to avoid hitting the limit of the api\n","\n","\n","    except requests.exceptions.HTTPError as errh: \n","        error_message = errh.args[0]\n","        vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}> failed. HTTP Error; error: <{error_message}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.ReadTimeout as errrt: \n","        vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}> failed. Time out; error: <{errrt}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.ConnectionError as conerr: \n","        vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}> failed. Connection error; error: <{conerr}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","    except requests.exceptions.RequestException as errex: \n","        vMessage = f\"deleting user <{vUserUPN}> from workspace <{vWorkspaceId}> failed. Exception request; error: <{errex}>\"\n","        print(f\"{vMessage}\")\n","        status = \"failed\"\n","\n","\n","    # return the status\n","    return status"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3295de51-8b19-4eca-82af-87e326a748a7"},{"cell_type":"markdown","source":["**Function to call a fabric api and return the correspondant dataframe**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f3788c30-4adf-4f93-8b9b-0ec73355b1f9"},{"cell_type":"code","source":["def perform_get_request(url, headers, debug_mode, extraction_type):\n","\n","    # the fabric client fails when making api calls to the onelake storage\n","    if extraction_type==\"file_system\":\n","        try:\n","            response = requests.get(url, headers = headers)\n","            return response\n","        except Exception as e:\n","            print(\"failed to call the api. exception:\", str(e))\n","            return None\n","    else:\n","        try:\n","            response = client.get(url, headers)\n","\n","            if response.status_code != 200:\n","                raise FabricHTTPException(response)\n","            else:\n","                return response\n","\n","        except FabricHTTPException as e:\n","            if debug_mode == \"yes\":\n","                print(\"failed to call the fabric api. exception:\", str(e))\n","            return None\n","\n","\n","def handle_response(response, debug_mode):\n","    if response is None:\n","        if debug_mode == \"yes\":\n","            print(\"response is None\")\n","        return None\n","    elif not response.text.strip():\n","        if debug_mode == \"yes\":\n","            print(\"response is empty\")\n","        return None\n","    else:\n","        try:\n","            # convert response to JSON\n","            response_data = response.json()\n","            response_content = json.loads(response.content)\n","            continuation_token = \"\" #response_data.get('continuationToken', None)\n","            continuation_uri = \"\" #response_data.get('continuationUri', None)\n","            return response_content, continuation_token, continuation_uri\n","        except ValueError:\n","            if debug_mode == \"yes\":\n","                print(\"failed to parse response as json\")\n","            return None\n","\n","\n","def json_to_dataframe(response_content, debug_mode, extraction_type):\n","    try:\n","        match extraction_type:           \n","            case \"audit_logs\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['activityEventEntities']])\n","                return result_dataframe\n","            case \"domains\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['domains']])\n","                return result_dataframe\n","            case \"external_data_shares\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"tenant_settings\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['tenantSettings']])\n","                return result_dataframe\n","            case \"capacities\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"connections\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"deployment_pipelines\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"gateways\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"shortcuts\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            case \"file_system\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['paths']])\n","                return result_dataframe\n","            case \"onelake_access\":\n","                result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['value']])\n","                return result_dataframe\n","            # case \"relations\":\n","            #     result_dataframe = pd.concat([pd.json_normalize(x) for x in response_content['relations']])\n","            #     return result_dataframe   \n","\n","    except Exception as e:\n","        if debug_mode == \"yes\":\n","            print(f\"failed to generate the required dataframe. exception: {str(e)}\")      \n","              \n","\n","def append_to_global_df(result_dataframe):\n","    global api_call_global_dataframe\n","    if not result_dataframe.empty:\n","        api_call_global_dataframe = pd.concat([api_call_global_dataframe, result_dataframe], ignore_index=True)\n","\n","def api_call_main(url, headers, debug_mode, extraction_type):\n","\n","    # set boolean vaule to continue to the next interval (in case response has a paging url)\n","    continue_to_next_interval = True\n","\n","    # while loop the boolean is true\n","    while continue_to_next_interval:\n","\n","        # perform the GET request\n","        response = perform_get_request(url, headers, debug_mode, extraction_type)\n","        # print(json.loads(response.text))\n","\n","        # # handle the response\n","        response_content, continuation_token, continuation_uri = handle_response(response, debug_mode)\n","        # print(response_content, continuation_token, continuation_uri)\n","\n","        # convert to a dataframe\n","        result_dataframe = json_to_dataframe(response_content, debug_mode, extraction_type)\n","\n","        # append to the global dataframe\n","        append_to_global_df(result_dataframe)\n","\n","        # while there is a continuation token, request the next continuation url\n","        # continuation_count = 0\n","        while continuation_token:\n","            # continuation_count +=1\n","            # print(f\"continuation {continuation_count}\")\n","            response = perform_get_request(continuation_uri, headers, debug_mode, extraction_type) \n","            response_content, continuation_token, continuation_uri = handle_response(response, debug_mode)\n","            result_dataframe = json_to_dataframe(response_content, debug_mode, extraction_type)\n","            append_to_global_df(result_dataframe)\n","\n","        # if no error exit the while loop\n","        continue_to_next_interval = False"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3668c60-dbb5-4e17-9925-af47e6c4a185"},{"cell_type":"markdown","source":["**Function to create a fabric item**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33d587ba-36a1-44a0-a0e7-8bd335e0c150"},{"cell_type":"code","source":["def create_or_update_fabric_item(url, headers, body, call_type, operation, workspace_id, item_name, item_type, sleep_in_seconds, debug_mode):\n","\n","    vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}>\"\n","    print(vMessage)\n","    \n","    if call_type == \"post\":\n","\n","        # # json body\n","        # vJsonBody = {\n","        #     \"displayName\": f\"{item_name}\",\n","        #     \"type\": f\"{item_type}\",\n","        #     \"description\": f\"{item_type} {item_name} created by fabric notebook\"\n","        # }\n","\n","        try:\n","            # post the assignment\n","            if body is None:\n","                response = client.post(url, headers=headers)\n","            else:\n","                response = client.post(url, headers=headers, json=body)\n","\n","            if response.status_code not in (200, 201, 202):\n","                raise FabricHTTPException(response)\n","            else:\n","\n","                # check status\n","                if response.status_code == 201: # if status is 201 then the create item succeeded\n","\n","                    vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}> succeeded\"\n","                    print(f\"{vMessage}\")\n","\n","                elif response.status_code == 202: # if status is 202 then the create item is in progress\n","                    \n","                    vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}> is in progress\"\n","                    print(vMessage)\n","\n","                    # get the operation url from the header location\n","                    # doc https://learn.microsoft.com/en-us/rest/api/fabric/articles/long-running-operation\n","                    operation_url = response.headers.get(\"Location\")\n","\n","                    # vMessage = f\"operation url: <{operation_url}>\"\n","\n","                    # monitor the operation\n","                    while True:\n","\n","                        # sleep the specified time --> this wait time might need adjustment\n","                        time.sleep(sleep_in_seconds)  \n","\n","                        # check the operation\n","                        operation_response = client.get(operation_url, headers=headers) \n","\n","                        if operation_response.status_code == 200:\n","\n","                            vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}> succeeded\"\n","                            print(f\"{vMessage}\")\n","                            break\n","\n","                        else:\n","                            vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}> failed\"\n","                            print(f\"{vMessage}\")\n","                            break\n","\n","                else: # any other status is a failure\n","                    vMessage = f\"{operation} {item_type} <{item_name}> in workspace <{workspace_id}> failed\"\n","                    print(f\"{vMessage}\")\n","\n","                    # retry: \n","                    vMessage = f\"second attempt - {operation} {item_type} <{item_name}> in workspace <{workspace_id}>\"\n","                    print(f\"{vMessage}\")\n","                    create_item(url, headers, body, operation, workspace_id, item_name, item_type, sleep_in_seconds, debug_mode)\n","\n","        except FabricHTTPException as e:\n","            print(\"failed to call the fabric api. exception:\", str(e))\n","            return None\n","    else:\n","        try:\n","            response = requests.put(url, headers=headers, json=body)\n","            print(response.text)\n","        except Exception as e:\n","            print(\"failed to call the fabric api. exception:\", str(e))\n","            return None\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f8beb4f-08be-4814-93ec-1b848593665c"},{"cell_type":"markdown","source":["**Function to recursively replace placeholders in a json object**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8ba72b88-633e-4fdf-9557-312985e565c3"},{"cell_type":"code","source":["def replace_placeholders_in_json(obj, inputs_for_json):\n","    if isinstance(obj, dict):\n","        return {k: replace_placeholders_in_json(v, inputs_for_json) for k, v in obj.items()}\n","    elif isinstance(obj, list):\n","        return [replace_placeholders_in_json(item, inputs_for_json) for item in obj]\n","    elif isinstance(obj, str):\n","        for key, value in inputs_for_json.items():\n","            obj = obj.replace(f\"{{{key}}}\", str(value))\n","        return obj\n","    else:\n","        return obj"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0f07bc69-1bdc-4df9-99c6-3f6cfd407a61"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}