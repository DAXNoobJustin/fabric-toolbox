{"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b25c1cb8-9265-4d80-b7ab-8ca075a88882"},{"cell_type":"code","source":["import notebookutils\n","import pandas as pd\n","import datetime, time\n","import re,json\n","import sempy\n","import sempy.fabric as fabric\n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col,current_timestamp,lit\n","import sempy_labs as labs\n","from sempy_labs import migration, directlake\n","from sempy_labs import lakehouse as lake\n","from sempy_labs import report as rep\n","from sempy_labs.tom import connect_semantic_model\n","\n","\n","# workspaceutils - common utilities\n","\n","# instantiate the Fabric rest client\n","client = fabric.FabricRestClient()\n","pbiclient = fabric.PowerBIRestClient()\n","\n","# loading a dataframe of connections to perform an ID lookup if required \n","df_conns = labs.list_connections()\n","\n","# get the current workspace ID based on the context of where this notebook is run from\n","thisWsId = notebookutils.runtime.context['currentWorkspaceId'] \n","\n","# Gets the status of a capacity\n","def get_capacity_status(p_target_cap):\n","    dfC = fabric.list_capacities()\n","    dfC_filt = dfC[dfC[\"Id\"] == p_target_cap]\n","    return dfC_filt['State'].iloc[0]\n","\n","# this function attempts to save a dataframe which can be either a pandas dataframe or spark dataframe\n","def saveTable(pdf,table_name, mode='overwrite'):\n","    if mode=='append' and not any(table.name == table_name for table in spark.catalog.listTables()):\n","            mode = 'overwrite'\n","\n","    if (isinstance(pdf, pd.DataFrame) and pdf.empty) or \\\n","       (isinstance(pdf, DataFrame) and pdf.isEmpty()):\n","        return('No ' + table_name + ' found, nothing to save (Dataframe is empty)')\n","    if not isinstance(pdf, DataFrame):\n","        pdf = spark.createDataFrame(pdf)\n","\n","    df = pdf.select([col(c).alias(\n","            c.replace( '(', '')\n","            .replace( ')', '')\n","            .replace( ',', '')\n","            .replace( ';', '')\n","            .replace( '{', '')\n","            .replace( '}', '')\n","            .replace( '\\n', '')\n","            .replace( '\\t', '')\n","            .replace( ' ', '_')\n","            .replace( '.', '_')\n","        ) for c in pdf.columns])\n","    #display(df)\n","    df.withColumn(\"metaTimestamp\",current_timestamp()).write.mode(mode) \\\n","      .option(\"mergeSchema\", \"true\").saveAsTable(table_name)\n","    return(str(df.count()) +' records saved to the '+table_name + ' table.')\n","\n","def saveCapacityMeta():\n","    spark.sql(\"drop table if exists capacitiess\")\n","    df = fabric.list_capacities()\n","    print(saveTable(df,\"capacities\"))\n","\n","def saveWorkspaceMeta(suppress_output=False):\n","    spark.sql(\"drop table if exists workspaces\")\n","    df = fabric.list_workspaces()\n","    #display(df)\n","    if not suppress_output:\n","        print(saveTable(df,\"workspaces\"))\n","    else:\n","        saveTable(df,\"workspaces\")\n","\n","def saveItemMeta(verbose_logging,ws_ignore_list, ws_ignore_like_list, list_of_workspaces_to_recover):\n","    all_items = []\n","    spark.sql(\"drop table if exists items\")\n","    saveResults = saveWorkspaceMeta()\n","\n","    wsitemssql = \"SELECT distinct ID,Type,Name FROM workspaces where 1=1\"\n","\n","    if len(ws_ignore_like_list)>0:\n","        for notlike in ws_ignore_like_list:\n","            wsitemssql  = wsitemssql + \" and name not like '\" + notlike + \"'\"\n","\n","    if len(ws_ignore_list)>0:\n","        wsitemssql  = wsitemssql + \" and name not in ('\" + \"', '\".join(ws_ignore_list)+ \"') \"\n","\n","    if len(list_of_workspaces_to_recover)>0:\n","        wsitemssql = wsitemssql+\" and Name like '%_DR'\" #in ('\" +  \"', '\".join(list_of_workspaces_to_recover)+ \"') \"\n","\n","    df = spark.sql(wsitemssql).collect()\n","\n","    for i in df:\n","        if verbose_logging:\n","            print('Getting items for workspace ' + i['Name'] + '...')\n","        if i['Type'] == 'Workspace':\n","            url = \"/v1/workspaces/\" + i['ID'] + \"/items\"\n","        try:\n","            itmresponse = client.get(url)\n","            #print(itmresponse.json()) \n","            all_items.extend(itmresponse.json()['value']) \n","        except Exception as error:\n","            errmsg =  \"Couldn't get list of items for workspace \" + i['Name'] + \"(\"+ i['ID'] + \").\"\n","            if (verbose):\n","                 errmsg = errmsg + \"Error: \"+str(error)\n","            print(str(errmsg))\n","    itmdf=spark.read.json(sc.parallelize(all_items))\n","    print(saveTable(itmdf,'items'))\n","\n","def saveReportMeta(verbose_logging, only_secondary=False,secondary_ws_suffix='', ws_ignore_list=[], ws_ignore_like_list=[]):\n","    all_report_data = []\n","    table_name = 'reports'\n","    spark.sql(\"Drop table if exists \"+ table_name)\n","    reportsql = \"SELECT distinct ID,Type,Name FROM workspaces where Type!='AdminInsights'\"\n","    \n","    if len(ws_ignore_like_list)>0:\n","        for notlike in ws_ignore_like_list:\n","            reportsql  = reportsql + \" and name not like '\" + notlike + \"'\"\n","    if len(ws_ignore_list)>0:\n","        reportsql  = reportsql + \" and name not in ('\" + \"', '\".join(ws_ignore_list)+ \"') \"\n","\n","    if only_secondary:\n","        reportsql = reportsql + \" and Name like '%\"+secondary_ws_suffix+\"'\" \n","    reportdf = spark.sql(reportsql).collect()\n","\n","    for idx,i in enumerate(reportdf):\n","        if i['Type'] == 'Workspace':\n","            try:\n","                if verbose_logging:\n","                    print('Retreiving reports for workspace '+ i['Name'] + '...')\n","                dfwsreports = fabric.list_reports(i['ID'] )   \n","                if idx == 0:\n","                        dfallreports = dfwsreports\n","                else:\n","                        dfallreports = pd.concat([dfallreports, dfwsreports], ignore_index=True, sort=False)\n","            except WorkspaceNotFoundException as e:\n","                print(\"WorkspaceNotFoundException:\", e)\n","            except FabricHTTPException as e:\n","                print(\"Caught a FabricHTTPException. Check the API endpoint, authentication.\")\n","\n","            except Exception as error:\n","                errmsg =  \"Couldn't retreive report details for workspace \" + i['Name'] + \"(\"+ i['ID'] + \"). Error: \"+str(error)\n","                print(str(errmsg))\n","\n","    dfallreports = dfallreports.drop('Subscriptions', axis=1)\n","    dfallreports = dfallreports.drop('Users', axis=1)\n","    print(saveTable(dfallreports,'reports'))\n","\n","def get_lh_object_list(base_path,data_types = ['Tables', 'Files'])->pd.DataFrame:\n","\n","    '''\n","    Function to get a list of tables for a lakehouse\n","    adapted from https://fabric.guru/getting-a-list-of-folders-and-delta-tables-in-the-fabric-lakehouse\n","    This function will return a pandas dataframe containing names and abfss paths of each folder for Files and Tables\n","    '''\n","    #data_types = ['Tables', 'Files'] #for if you want a list of files and tables\n","    #data_types = ['Tables'] #for if you want a list of tables\n","\n","    df = pd.concat([\n","        pd.DataFrame({\n","            'name': [item.name for item in notebookutils.fs.ls(f'{base_path}/{data_type}/')],\n","            'type': data_type[:-1].lower() , \n","            'src_path': [item.path for item in notebookutils.fs.ls(f'{base_path}/{data_type}/')],\n","        }) for data_type in data_types], ignore_index=True)\n","\n","    return df\n","\n","def get_wh_object_list(schema_list,base_path)->pd.DataFrame:\n","\n","    '''\n","    Function to get a list of tables for a warehouse by schema\n","    '''\n","    data_type = 'Tables'\n","    dfs = []\n","\n","    for schema_prefix in schema_list:\n","        if notebookutils.fs.exists(f'{base_path}/{data_type}/{schema_prefix}/'):\n","            items = notebookutils.fs.ls(f'{base_path}/{data_type}/{schema_prefix}/')\n","            if items:  # Check if the list is not empty\n","                df = pd.DataFrame({\n","                    'schema': schema_prefix,\n","                    'name': [item.name for item in items],\n","                    'type': data_type[:-1].lower(),\n","                    'src_path': [item.path for item in items],\n","                })\n","                dfs.append(df)\n","\n","    if dfs:  # Check if the list of dataframes is not empty\n","        df = pd.concat(dfs, ignore_index=True)\n","    else:\n","        df = pd.DataFrame()  # Return an empty dataframe if no dataframes were created\n","\n","    return df\n","\n","def copy_lh_objects(table_list,workspace_src,workspace_tgt,lakehouse_src,lakehouse_tgt,recovered_object_suffix,fastcopy=True,usingIDs=False)->pd.DataFrame:\n","    # declare an array to keep the instrumentation\n","    cpresult = []\n","    # loop through all the tables to extract the source path \n","    for table in table_list.src_path:\n","        source = table\n","        destination = source.replace(f'abfss://{workspace_src}', f'abfss://{workspace_tgt}')\n","        if usingIDs:\n","            destination = destination.replace(f'{lakehouse_src}', f'{lakehouse_tgt}')\n","        else:\n","            destination = destination.replace(f'{lakehouse_src}.Lakehouse', f'{lakehouse_tgt}.Lakehouse') + recovered_object_suffix\n","        start_time =  datetime.datetime.now()\n","        if notebookutils.fs.exists(destination):\n","             notebookutils.fs.rm(destination, True)\n","        if fastcopy:\n","            # use fastcopy util which is a python wrapper to azcopy\n","            notebookutils.fs.fastcp(source+'/*', destination+'/', True)\n","        else:\n","            notebookutils.fs.cp(source, destination, True)\n","\n","        # recording the timing and add it to the results list\n","        end_time = datetime.datetime.now()\n","        copyreslist = [source, destination, start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),  end_time.strftime(\"%Y-%m-%d %H:%M:%S\"), str((end_time - start_time).total_seconds())]\n","        cpresult.append(copyreslist)\n","    return pd.DataFrame(cpresult,columns =['source--------------------------------------','target--------------------------------------','start------------','end_time------------','elapsed seconds----'])\n","\n","def getItemId(wks_id,itm_name,itm_type):\n","    df = fabric.list_items(type=None,workspace=wks_id)\n","    #print(df)\n","    if df.empty:\n","        #print('No items found in workspace '+i['Name']+' (Dataframe is empty)')\n","        return 'NotExists'\n","    else:\n","        #display(df)\n","        #print(df.query('\"Display Name\"=\"'+itm_name+'\"'))\n","        if itm_type != '':\n","          newdf= df.loc[(df['Display Name'] == itm_name) & (df['Type'] == itm_type)]['Id']\n","        else:\n","          newdf= df.loc[(df['Display Name'] == itm_name)]['Id']  \n","        if newdf.empty:\n","          return 'NotExists'\n","        else:\n","          return newdf.iloc[0]\n","\n","###### Function to create DW recovery pipeline\n","def createDWrecoverypl(ws_id,pl_name = 'Recover_Warehouse_Data_From_DR'):\n","  client = fabric.FabricRestClient()\n","\n","  dfurl= \"v1/workspaces/\"+ ws_id + \"/items\"\n","  payload = { \n","  \"displayName\": pl_name, \n","  \"type\": \"DataPipeline\", \n","  \"definition\": { \n","    \"parts\": [ \n","      { \n","        \"path\": \"pipeline-content.json\", \n","        \"payload\":  \"{
    "properties": {
        "activities": [
            {
                "name": "IterateSchemaTables",
                "type": "ForEach",
                "dependsOn": [],
                "typeProperties": {
                    "items": {
                        "value": "@pipeline().parameters.tablesToCopy",
                        "type": "Expression"
                    },
                    "batchCount": 20,
                    "activities": [
                        {
                            "name": "CopyWarehouseTables",
                            "type": "Copy",
                            "dependsOn": [
                                {
                                    "activity": "Set table",
                                    "dependencyConditions": [
                                        "Succeeded"
                                    ]
                                }
                            ],
                            "policy": {
                                "timeout": "0.12:00:00",
                                "retry": 2,
                                "retryIntervalInSeconds": 30,
                                "secureOutput": false,
                                "secureInput": false
                            },
                            "typeProperties": {
                                "source": {
                                    "type": "DataWarehouseSource",
                                    "queryTimeout": "02:00:00",
                                    "partitionOption": "None",
                                    "datasetSettings": {
                                        "annotations": [],
                                        "linkedService": {
                                            "name": "07a03006_d1b6_4a39_beb1_0bba2aaf5ff7",
                                            "properties": {
                                                "annotations": [],
                                                "type": "DataWarehouse",
                                                "typeProperties": {
                                                    "endpoint": "@pipeline().parameters.lakehouseConnStr",
                                                    "artifactId": "@pipeline().parameters.lakehouseId",
                                                    "workspaceId": "@pipeline().parameters.workspaceId"
                                                }
                                            }
                                        },
                                        "type": "DataWarehouseTable",
                                        "schema": [],
                                        "typeProperties": {
                                            "schema": "dbo",
                                            "table": {
                                                "value": "@concat(concat(item().schema,'_'),item().name)",
                                                "type": "Expression"
                                            }
                                        }
                                    }
                                },
                                "sink": {
                                    "type": "DataWarehouseSink",
                                    "allowCopyCommand": true,
                                    "tableOption": "autoCreate",
                                    "datasetSettings": {
                                        "annotations": [],
                                        "linkedService": {
                                            "name": "0c03123a_d312_46c4_a8e7_5b4cad8f12d7",
                                            "properties": {
                                                "annotations": [],
                                                "type": "DataWarehouse",
                                                "typeProperties": {
                                                    "endpoint": "@pipeline().parameters.warehouseConnStr",
                                                    "artifactId": "@pipeline().parameters.warehouseId",
                                                    "workspaceId": "@pipeline().parameters.workspaceId"
                                                }
                                            }
                                        },
                                        "type": "DataWarehouseTable",
                                        "schema": [],
                                        "typeProperties": {
                                            "schema": "dbo",
                                            "table": {
                                                "value": "@item().name",
                                                "type": "Expression"
                                            }
                                        }
                                    }
                                },
                                "enableStaging": true,
                                "translator": {
                                    "type": "TabularTranslator",
                                    "typeConversion": true,
                                    "typeConversionSettings": {
                                        "allowDataTruncation": true,
                                        "treatBooleanAsNumber": false
                                    }
                                }
                            }
                        },
                        {
                            "name": "Set table",
                            "type": "SetVariable",
                            "dependsOn": [
                                {
                                    "activity": "Set schema",
                                    "dependencyConditions": [
                                        "Succeeded"
                                    ]
                                }
                            ],
                            "policy": {
                                "secureOutput": false,
                                "secureInput": false
                            },
                            "typeProperties": {
                                "variableName": "Tablename",
                                "value": {
                                    "value": "@item().name",
                                    "type": "Expression"
                                }
                            }
                        },
                        {
                            "name": "Set schema",
                            "type": "SetVariable",
                            "dependsOn": [],
                            "policy": {
                                "secureOutput": false,
                                "secureInput": false
                            },
                            "typeProperties": {
                                "variableName": "Schemaname",
                                "value": {
                                    "value": "@item().schema",
                                    "type": "Expression"
                                }
                            }
                        }
                    ]
                }
            }
        ],
        "parameters": {
            "lakehouseId": {
                "type": "string",
                "defaultValue": "0f0f6b7c-1761-41e6-896e-30014f16ff6d"
            },
            "tablesToCopy": {
                "type": "array",
                "defaultValue": [
                    {
                        "schema": "dbo",
                        "name": "Date"
                    },
                    {
                        "schema": "dbo",
                        "name": "Geography"
                    },
                    {
                        "schema": "dbo",
                        "name": "HackneyLicense"
                    },
                    {
                        "schema": "dbo",
                        "name": "Medallion"
                    },
                    {
                        "schema": "dbo",
                        "name": "Time"
                    },
                    {
                        "schema": "dbo",
                        "name": "Trip"
                    },
                    {
                        "schema": "dbo",
                        "name": "Weather"
                    }
                ]
            },
            "workspaceId": {
                "type": "string",
                "defaultValue": "1501143c-272f-4a2f-976a-7e55971e4c2b"
            },
            "warehouseId": {
                "type": "string",
                "defaultValue": "4d1bd951-99de-4bd7-b7bc-71c8f56db411"
            },
            "warehouseConnStr": {
                "type": "string",
                "defaultValue": "72wwbivi2ubejbrtmtaho32b4y-hqkacfjpe4xuvf3kpzkzohsmfm.datawarehouse.fabric.microsoft.com"
            },
            "lakehouseConnStr": {
                "type": "string",
                "defaultValue": "72wwbivi2ubejbrtmtaho32b4y-hqkacfjpe4xuvf3kpzkzohsmfm.datawarehouse.fabric.microsoft.com"
            }
        },
        "variables": {
            "Tablename": {
                "type": "String"
            },
            "Schemaname": {
                "type": "String"
            }
        },
        "lastModifiedByObjectId": "4aa20af7-94bd-4348-bef8-f8cbcd840d51",
        "lastPublishTime": "2024-11-13T15:52:52Z"
    }
}\", \n","        \"payloadType\": \"InlineBase64\" \n","      } \n","    ] \n","  } \n","}   \n","  \n","  response = json.loads(client.post(dfurl,json= payload).content)\n","  return response['id']\n","\n","def getWorkspaceRolesAssignments(pWorkspaceId):\n","    url = \"/v1/workspaces/\" +pWorkspaceId + \"/roleAssignments\"\n","    try:\n","        print('Attempting to connect workspace '+ i['Workspace_Name'])\n","        response = client.post(url,json= json.loads(payload))\n","        print(str(response.status_code) + response.text) \n","        success = True\n","    except Exception as error:\n","        errmsg =  \"Couldn't connect git to workspace \" + i['Workspace_Name'] + \"(\"+ i['Workspace_ID'] + \"). Error: \"+str(error)\n","        print(str(errmsg))\n","\n","\n","def long_running_operation_polling(uri,retry_after):\n","    try:\n","        print(f\"Polling long running operation ID {uri} has been started with a retry-after time of {retry_after} seconds.\")\n","        while True:\n","            response = client.get(uri)\n","            operation_state = response.json()\n","            print('operation state = '+str(operation_state))\n","            print(f\"Long running operation status: {operation_state['status']}\")\n","            if operation_state['status'] in [\"NotStarted\", \"Running\"]:\n","                time.sleep(retry_after)\n","            else:\n","                break\n","        if operation_state['status'] == \"Failed\":\n","            print(f\"The long running operation has been completed with failure. Error response: {json.dumps(operation_state['Error'])}\")\n","        else:\n","            print(\"The long running operation has been successfully completed.\")\n","            #response = client.get(uri+'/result')\n","            return operation_state['status']\n","    except Exception as e:\n","        print(f\"The long running operation has been completed with failure. Error response: {e}\")\n","\n","class noDefaultLakehouseException(Exception):\n","    pass\n","\n","\n","\n","from typing import Optional\n","from sempy_labs._helper_functions import (\n","    resolve_workspace_name_and_id,\n","    lro,\n","    _decode_b64,\n",")\n","import sempy_labs._icons as icons\n","\n","import base64\n","from typing import Optional, Tuple, List\n","from uuid import UUID\n","\n","\n","def update_data_pipeline_definition(\n","    name: str, pipeline_content: dict, workspace: Optional[str] = None\n","):\n","    \"\"\"\n","    Updates an existing data pipeline with a new definition.\n","\n","    Parameters\n","    ----------\n","    name : str\n","        The name of the data pipeline.\n","    pipeline_content : dict\n","        The data pipeline content (not in Base64 format).\n","    workspace : str, default=None\n","        The name of the workspace.\n","        Defaults to None which resolves to the workspace of the attached lakehouse\n","        or if no lakehouse attached, resolves to the workspace of the notebook.\n","    \"\"\"\n","\n","    (workspace, workspace_id) = resolve_workspace_name_and_id(workspace)\n","    client = fabric.FabricRestClient()\n","    pipeline_payload = base64.b64encode(json.dumps(pipeline_content).encode('utf-8')).decode('utf-8')\n","    pipeline_id = fabric.resolve_item_id(\n","        item_name=name, type=\"DataPipeline\", workspace=workspace\n","    )\n","\n","    request_body = {\n","        \"definition\": {\n","            \"parts\": [\n","                {\n","                    \"path\": \"pipeline-content.json\",\n","                    \"payload\": pipeline_payload,\n","                    \"payloadType\": \"InlineBase64\"\n","                }\n","            ]\n","        }\n","    }\n","\n","\n","    response = client.post(\n","        f\"v1/workspaces/{workspace_id}/items/{pipeline_id}/updateDefinition\",\n","        json=request_body,\n","    )\n","\n","    lro(client, response, return_status_code=True)\n","\n","    print(\n","        f\"{icons.green_dot} The '{name}' pipeline was updated within the '{workspace}' workspace.\"\n","    )\n","\n","def _is_valid_uuid(\n","    guid: str,\n","):\n","    \"\"\"\n","    Validates if a string is a valid GUID in version 4\n","\n","    Parameters\n","    ----------\n","    guid : str\n","        GUID to be validated.\n","\n","    Returns\n","    -------\n","    bool\n","        Boolean that indicates if the string is a GUID or not.\n","    \"\"\"\n","\n","    try:\n","        UUID(str(guid), version=4)\n","        return True\n","    except ValueError:\n","        return False\n","\n","import json\n","from jsonpath_ng import jsonpath, parse\n","from typing import Optional, Tuple, List\n","from uuid import UUID\n","\n","\n","# Swaps the connection properties of an activity belonging to the specified item type(s)\n","def swap_pipeline_connection(pl_json: dict, p_lookup_df: DataFrame,\n","                                p_item_type: List =['Warehouse','Lakehouse','Notebook'], \n","                                p_conn_from_to: Optional[List[Tuple[str,str]]]=[]):\n","\n","    def lookupItem(p_itm_id) -> Tuple[str]:\n","        #print(p_itm_id)\n","        if not p_lookup_df.filter(f\"old_item_id=='{p_itm_id}'\").isEmpty():\n","            return p_lookup_df.filter(f\"old_item_id=='{p_itm_id}'\").collect()[0][1:8]\n","        else:\n","            return['','','','','','','']\n","\n","    source_nb_id=''\n","    source_id, target_id, itm_name, source_ws_id, source_ws_name, target_ws_id, target_ws_name = lookupItem('0000-0000-0000-0000')\n","  \n","    if 'Warehouse' in p_item_type or 'Lakehouse' in p_item_type:\n","        ls_expr = parse('$..linkedService')\n","        for endpoint_match in ls_expr.find(pl_json):\n","            if endpoint_match.value['properties']['type'] == 'DataWarehouse' and 'Warehouse' in p_item_type:\n","                # only update the warehouse if it was located in the source workspace i.e. we will update the properties to the target workspace if the warehouse resided in the same workspace as the pipeline\n","                #print(endpoint_match.value)\n","                warehouse_id = endpoint_match.value['properties']['typeProperties']['artifactId']\n","                if _is_valid_uuid(warehouse_id): #only swap if valid uuid otherwise most likely it is parameterised \n","                    print(f\"warehouse id = {warehouse_id}\")\n","                    warehouse_endpoint = endpoint_match.value['properties']['typeProperties']['endpoint']\n","                    #print(warehouse_endpoint)\n","                    source_id, target_id, itm_name, source_ws_id, source_ws_name, target_ws_id, target_ws_name = lookupItem(warehouse_id)\n","                    if source_id !='': # check whether any corresponding values were returned form the lookup\n","                        print(f\"changing warehouse {itm_name} (source_id={source_id} target_id={target_id}) from source workspace {source_ws_name} ({source_ws_id}) to target workspace {target_ws_name} ({target_ws_id})\")\n","                        # look up the connection string for the warehouse in the target workspace\n","                        whurl  = f\"v1/workspaces/{target_ws_id}/warehouses/{target_id}\"\n","                        whresponse = client.get(whurl)\n","                        lhconnStr = whresponse.json()['properties']['connectionString']\n","                        endpoint_match.value['properties']['typeProperties']['artifactId'] = target_id\n","                        endpoint_match.value['properties']['typeProperties']['workspaceId'] = target_ws_id\n","                        endpoint_match.value['properties']['typeProperties']['endpoint'] = lhconnStr\n","                        #print(endpoint_match.value)\n","                        ls_expr.update(endpoint_match,endpoint_match.value)\n","                    else:\n","                        print(f\"Could not find associated IDs for warehouse {warehouse_id}\")\n","                else:\n","                    print(f\"Lakehouse was not a valid UUID and was parameterised with {source_nb_id} therefore ignoring\")\n","\n","            if endpoint_match.value['properties']['type'] == 'Lakehouse' and 'Lakehouse' in p_item_type:\n","                #print(endpoint_match.value)\n","                lakehouse_id = endpoint_match.value['properties']['typeProperties']['artifactId']\n","                if _is_valid_uuid(lakehouse_id):  #only swap if valid uuid otherwise most likely it is parameterised \n","                    print(f\"lakehouse id = {lakehouse_id}\")\n","                    source_id, target_id, itm_name, source_ws_id, source_ws_name, target_ws_id, target_ws_name = lookupItem(lakehouse_id)\n","                    if source_id != '':\n","                        print(f\"changing lakehouse {itm_name} (source_id={source_id} target_id={target_id}) from source workspace {source_ws_name} ({source_ws_id}) to target workspace {target_ws_name} ({target_ws_id})\")\n","                        # find the lakehouse id of the lakehouse with the same name in the target workspace\n","                        endpoint_match.value['properties']['typeProperties']['artifactId'] = target_id\n","                        endpoint_match.value['properties']['typeProperties']['workspaceId'] = target_ws_id\n","                        ls_expr.update(endpoint_match,endpoint_match.value)\n","                        #    print(endpoint_match.value)\n","                    else:\n","                        print(f\"Could not find associated IDs for lakehouse {lakehouse_id}\")\n","                else:\n","                    print(f\"Lakehouse was not a valid UUID and was parameterised with {source_nb_id} therefore ignoring\")\n","\n","\n","    if 'Notebook' in p_item_type: \n","        ls_expr = parse('$..activities')\n","\n","        for endpoint_match in ls_expr.find(pl_json):\n","            for activity in endpoint_match.value:\n","                #print(activity['type'])\n","                if activity['type']=='TridentNotebook' and 'Notebook' in p_item_type: #only update if the notebook was in the same workspace as the pipeline\n","                    source_nb_id = activity['typeProperties']['notebookId']\n","                    if _is_valid_uuid(source_nb_id):  \n","                        source_id, target_id, itm_name, source_ws_id, source_ws_name, target_ws_id, target_ws_name = lookupItem(source_nb_id)\n","                        if source_id != '':\n","                            print(f\"changing notebook {itm_name} (source_id={source_id} target_id={target_id}) from source workspace {source_ws_name} ({source_ws_id}) to target workspace {target_ws_name} ({target_ws_id})\")\n","                            activity['typeProperties']['notebookId']=target_id\n","                            activity['typeProperties']['workspaceId']=target_ws_id\n","                            #ls_expr.update(endpoint_match,endpoint_match.value)\n","                        else:\n","                            print(f\"Could not find associated IDs for notebook {source_nb_id}\")\n","                    else:\n","                        print(f\"Notebook activity was not a valid UUID and was parameterised with {source_nb_id} therefore ignoring\")\n","    if p_conn_from_to:\n","        for ti_conn_from_to in p_conn_from_to:\n","            if not _is_valid_uuid(ti_conn_from_to[0]):\n","                #print('Connection from is string '+ str(ti_conn_from_to[0]))\n","                dfC_filt = df_conns[df_conns[\"Connection Name\"] == ti_conn_from_to[0]]       \n","                connId_from = dfC_filt['Connection Id'].iloc[0]     \n","            else:\n","                connId_from = ti_conn_from_to[0]\n","\n","            if not _is_valid_uuid(ti_conn_from_to[1]):\n","                #print('Connection from is string '+ str(ti_conn_from_to[1]))\n","                dfC_filt = df_conns[df_conns[\"Connection Name\"] == ti_conn_from_to[1]]       \n","                connId_to = dfC_filt['Connection Id'].iloc[0]     \n","            else:\n","                connId_to = ti_conn_from_to[1]\n","\n","            ls_expr = parse('$..externalReferences')\n","            for externalRef in ls_expr.find(pl_json):\n","                if externalRef.value['connection']==connId_from:\n","                    print('Changing connection from '+str(connId_from))\n","                    externalRef.value['connection']=connId_to\n","                    ls_expr.update(externalRef,externalRef.value)\n","                    print('to '+str(connId_to))\n","\n","    return pl_json\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d251b14-c796-4ba7-9043-8dc6a1ea907a"},{"cell_type":"code","source":["# temporary function to fix a bug raised with SLL. To be removed once PR #787 is live.\n","from sempy_labs._helper_functions import get_direct_lake_sql_endpoint\n","\n","def get_direct_lake_source(\n","    dataset: str | UUID, workspace: Optional[str | UUID] = None\n",") -> Tuple[str, str, UUID, UUID]:\n","    \"\"\"\n","    Obtains the source information for a direct lake semantic model (if the source is located in the same workspace as the semantic model).\n","\n","    Parameters\n","    ----------\n","    dataset : str | uuid.UUID\n","        The name or ID of the semantic model.\n","    workspace : str | uuid.UUID, default=None\n","        The Fabric workspace name or ID.\n","        Defaults to None which resolves to the workspace of the attached lakehouse\n","        or if no lakehouse attached, resolves to the workspace of the notebook.\n","\n","    Returns\n","    -------\n","    Tuple[str, str, UUID, UUID]\n","        If the source of the direct lake semantic model is a lakehouse this will return: 'Lakehouse', Lakehouse Name, SQL Endpoint Id, Workspace Id\n","        If the source of the direct lake semantic model is a warehouse this will return: 'Warehouse', Warehouse Name, Warehouse Id, Workspace Id\n","        If the semantic model is not a Direct Lake semantic model, it will return None, None, None.\n","    \"\"\"\n","\n","    from sempy_labs._helper_functions import get_direct_lake_sql_endpoint\n","\n","    (workspace_name, workspace_id) = resolve_workspace_name_and_id(workspace)\n","    sql_endpoint_id = get_direct_lake_sql_endpoint(dataset=dataset, workspace=workspace)\n","    dfI = fabric.list_items(workspace=workspace)\n","    dfI_filt = dfI[(dfI[\"Id\"] == sql_endpoint_id) & (dfI[\"Type\"].isin([\"SQLEndpoint\",\"Warehouse\"]))]\n","\n","    artifact_type, artifact_name, artifact_id = None, None, None\n","\n","    if not dfI_filt.empty:\n","        artifact_name = dfI_filt[\"Display Name\"].iloc[0]\n","        artifact_id = dfI[\n","            (dfI[\"Display Name\"] == artifact_name)\n","            & (dfI[\"Type\"].isin([\"Lakehouse\", \"Warehouse\"]))\n","        ][\"Id\"].iloc[0]\n","        artifact_type = dfI[\n","            (dfI[\"Display Name\"] == artifact_name)\n","            & (dfI[\"Type\"].isin([\"Lakehouse\", \"Warehouse\"]))\n","        ][\"Type\"].iloc[0]\n","\n","    return artifact_type, artifact_name, artifact_id, workspace_id\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3c9ed09-3d63-481e-b5db-d156c6535d1b"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}