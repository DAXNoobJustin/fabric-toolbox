{"cells":[{"cell_type":"markdown","source":["To run with higer concurrency you'll need to scale up the VM.  By default it runs with 4 cores.  To add a code cell below this that looks like:\n","\n","```\n","%%configure -f\n","{\n","    \"vCores\": 16,// Recommended values: [4, 8, 16, 32, 64], Fabric will allocate matched memory according to the specified vCores.\n","}\n","```\n","\n","Note that this will increase the notebook startup time as a VM will need to be spun-up.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dc7e11c3-ae97-470b-8117-c2aa73ba1548"},{"cell_type":"markdown","source":["%%configure -f\n","{\n","    \"vCores\": 4\n","}"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c29649ef-f374-4e4d-afa4-d9881c0837ec"},{"cell_type":"code","source":["import uuid\n","import sempy.fabric\n","import pandas as pd\n","import polars as pl\n","import os\n","from deltalake import DeltaTable\n","from deltalake.writer import write_deltalake\n","import sempy\n","import time \n","\n","\n","\n","load_test_name = \"DIAD\"                                                                 #name of test for logging\n","dataset = \"DIAD Final Report with RLS\"                                                  #name of the semantic model to test\n","workspace = \"Fabric Load Testing\"                                                       #workspace containing the semantic model to test \"None\" for the current workspace\n","queryfile = \"/lakehouse/default/Files/PerfScenarios/DIAD/PowerBIPerformanceData.json\"   #Power BI Desktop performance analyzer file containing the use case to test\n","concurrent_threads = 6                                                                  #number of concurrent threads to test\n","delay_sec = 4                                                                           #number of seconds each user waits between iterations of the use case\n","iterations = 3                                                                          #number of iterations run by each user\n","\n","\n","ts=time.strftime(\"%Y%m%d-%H%M%S\")\n","loadtestId:str = f\"{load_test_name}-{ts}\"\n","print(loadtestId)\n","\n","lakehouseId = sempy.fabric.get_lakehouse_id()\n","workspaceId = sempy.fabric.get_workspace_id()\n","\n","# Path for storing CSV files during run\n","folder_path = f\"/lakehouse/default/Files/PerfScenarios/logs/{loadtestId}\"\n","# Used for writing combined logs\n","#table_path = f'abfss://{workspaceId}@msit-onelake.dfs.fabric.microsoft.com/{lakehouseId}/Tables/dbo/logs' \n","\n","#Create folder dedicated to logs from this run only\n","notebookutils.fs.mkdirs(folder_path)\n","\n","users = []\n","              \n","\n","args = { \n","    \"xmla_endpoint\" : None, #defaults to current workspace's endpoint\n","    \"perf_analyzer_filename\" : queryfile , \n","    \"model\" : dataset,\n","    \"roles\" : None,\n","    \"customdata\" : None,\n","    \"effective_username\" : None,\n","    \"iterations\" : iterations,\n","    \"delay_sec\" : 1,\n","    \"loadtestId\" : loadtestId ,\n","    \"threadId\" : 0 ,\n","    \"concurrent_threads\" : concurrent_threads,\n","    \"useRootDefaultLakehouse\": True\n","}\n","\n","activity =  {\n","            \"name\": \"RunPerfScenario\", # activity name, must be unique\n","            \"path\": \"RunPerfScenario\", # notebook path\n","            \"timeoutPerCellInSeconds\": 9000, # max timeout for each cell, default to 90 seconds\n","            \"args\": {\"param1\": \"value1\"}, # notebook parameters\n","            \"workspace\": None, # workspace name, default to current workspace\n","            \"retry\": 0, # max retry times, default to 0\n","            \"retryIntervalInSeconds\": 0, # retry interval, default to 0 seconds\n","            \"dependencies\": [] # list of activity names that this activity depends on\n","           }\n","\n","\n","DAG = {\n","    \"activities\": [],\n","    \"timeoutInSeconds\": 43200, # max timeout for the entire pipeline, default to 12 hours\n","    \"concurrency\": 25 # max number of notebooks to run concurrently, default to 25\n","}\n","DAG[\"concurrency\"] = concurrent_threads\n","\n","for i in range(concurrent_threads):\n","    a = activity.copy()\n","    a[\"name\"] = f\"{a['name']}_{i}\"\n","    this_args = args.copy()\n","    if (len(users)>0):\n","        user = users[i%len(users)]\n","        this_args[\"effective_username\"] = user \n","        #this_args[\"customdata\"] = user\n","\n","    this_args[\"threadId\"] = i\n","    a[\"args\"] = this_args\n","\n","    DAG[\"activities\"].append(a)\n","    \n","# print(DAG)\n","print('running load test')\n","try:\n","\n","    ####################################\n","    ##  Run the parallel threads here ##\n","    ####################################\n","\n","    results = notebookutils.notebook.runMultiple(DAG) \n","\n","\n","except Exception as e:\n","    first_result = results[list(e.result)[0]]\n","    print('Notebook failed.  First Result Exception: ')\n","    print(first_result.get('exception',None))\n","print('load test complete')\n","\n","# Consolodate CSV log files of results into single dataframe\n","df_list = []\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.csv'):\n","        file_path = os.path.join(folder_path, filename)\n","        polars_df = pl.read_csv(file_path)\n","        # Need to store Time using format that will work for Direct Lake\n","\n","        polars_df = (polars_df\n","            .with_columns([\n","                pl.col(\"start_time_dt\").str.to_datetime(time_unit=\"ms\").dt.truncate(\"1s\").alias(\"start_time_s\").dt.replace_time_zone(time_zone=\"UTC\")\n","                ])\n","            )\n","\n","        polars_df = (polars_df\n","            .with_columns([\n","                pl.col(\"start_time_dt\").str.to_datetime(time_unit=\"ms\").alias(\"start_time_dt\").dt.replace_time_zone(time_zone=\"UTC\")\n","                ])\n","            )\n","\n","        df_list.append(polars_df)\n","\n","combined_df = pl.concat(df_list)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"jupyter":{"source_hidden":false}},"id":"dc3d30be-21a7-428d-84aa-25ca26d6ac3f"},{"cell_type":"code","source":["combined_df = combined_df.with_columns(pl.col(\"start_time_s\").cast(pl.Datetime).alias(\"start_time_s_dt\"))\n","\n","\n","combined_df = combined_df.with_columns(\n","    combined_df.group_by(\"start_time_s_dt\")\n","      .agg(pl.col(\"duration\").mean().alias(\"avg1\"))\n","      .join(combined_df, on=\"start_time_s_dt\")\n","      .select(\"avg1\")\n",")\n","\n","combined_df = combined_df.with_columns(\n","    combined_df.group_by(\"start_time_s_dt\")\n","      .agg(pl.col(\"duration\").quantile(0.9).alias(\"p90\"))\n","      .join(combined_df, on=\"start_time_s_dt\")\n","      .select(\"p90\")\n",")\n","\n","combined_df = combined_df.with_columns(\n","    combined_df.group_by(\"start_time_s_dt\")\n","      .agg(pl.col(\"duration\").quantile(0.5).alias(\"p50\"))\n","      .join(combined_df, on=\"start_time_s_dt\")\n","      .select(\"p90\")\n",")\n","\n","display(combined_df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"jupyterDisplayViewState":{"tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":[],"seriesFieldKeys":[],"aggregationType":"sum","isStacked":false,"binsNumber":10,"wordFrequency":"-1"},"viewOptionsGroup":[{"tabItems":[{"type":"table","name":"Table","key":"0","options":{}},{"type":"chart","key":"2-4hxp","name":"Chart 2","options":{"chartType":"line","categoryFieldKeys":["12","17"],"seriesFieldKeys":["10","18"],"aggregationType":"avg","isStacked":false,"binsNumber":10,"wordFrequency":"-1","title":"Avg of start_time by visual_name","subtitle":"Description of the chart","showDataLabels":true,"theme":"default","xAxisStyle":{"scale":"category"}}}]}]}},"id":"bb04a7c8-b884-4d4e-8622-548484c2f3a5"},{"cell_type":"code","source":["ctx = pl.SQLContext(test_results=combined_df, eager=True)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c9bb9d8a-9373-493e-8ab0-bbfd66c9991c"},{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"jupyter":{"outputs_hidden":true}},"id":"00891f53-ea9c-488a-bbe8-bee2e140e04b"},{"cell_type":"code","source":["import sempy_labs \n","\n","topq= ctx.execute(\"\"\"\n","select query, avg(duration) avg_duration\n","from test_results\n","group by query\n","order by avg_duration desc\n","\"\"\")\n","\n","queries = topq['query'].to_list()\n","avg_duration = topq[0]['avg_duration']\n","\n","columns = sempy_labs.get_dax_query_dependencies(dataset=dataset, workspace=workspace, dax_string=queries).sort_values(by='Total Size',ascending=False)\n","display(columns)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"006822ec-2229-4820-86c0-5b62e2705d3a"},{"cell_type":"code","source":["ctx.execute(\"\"\"\n","select *\n","from test_results\n","\"\"\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"47c2ed17-bdd7-445f-8af4-1253b61f0b7d"},{"cell_type":"code","source":["ctx.execute(\"\"\"\n","select visual_name, avg(duration) avg_duration, count(*) as query_count, avg(rows) avg_rows\n","from test_results\n","group by visual_name\n","order by avg_duration desc\n","\"\"\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c0471abf-408c-4486-9b89-f2daefb0564b"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.11"},"kernelspec":{"display_name":"synapse_pyspark","language":null,"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"3d65e297-8cce-4299-8756-de9c681b8cee","default_lakehouse_name":"LH","default_lakehouse_workspace_id":"853dcf2b-5779-4681-8f73-1f1e8b3d292d","known_lakehouses":[{"id":"3d65e297-8cce-4299-8756-de9c681b8cee"}]}}},"nbformat":4,"nbformat_minor":5}